{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satyajitnayak20/Diabetic-Retinopathy-Detection-using-Machine-Learning-and-Texture-Features/blob/main/Feature_Selection_Diabatic_retinopathy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8Puqf8Nmg7p4",
        "outputId": "34025265-aafb-4ec7-88d2-d4da6bc5e041"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python-headless) (2.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.14.1)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (3.4.2)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (11.1.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.3.30)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.14.1)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (3.4.2)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (11.1.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.3.30)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.14.1)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (3.4.2)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (11.1.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.3.30)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.14.1)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (3.4.2)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (11.1.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.3.30)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install opencv-python-headless\n",
        "\n",
        "!pip install numpy\n",
        "\n",
        "!pip install pandas\n",
        "\n",
        "!pip install scikit-image\n",
        "\n",
        "!pip install scikit-learn\n",
        "!pip install tqdm\n",
        "!pip install -U scikit-image\n",
        "!pip install scikit-image --upgrade\n",
        "!pip install -U scikit-image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yHlQCRpXawlg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d17405a2-8b16-4da3-ad24-c1285b6f692f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "04BUyJuvAw0A"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "m2AZyaR__CzO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-atzYUdMcMmO"
      },
      "outputs": [],
      "source": [
        "# import cv2\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# from skimage.feature import graycomatrix, graycoprops\n",
        "# from skimage.measure import shannon_entropy\n",
        "\n",
        "# def feature_extraction(path_to_folder, class_label):\n",
        "#     data_list = []\n",
        "#     for img_file in os.listdir(path_to_folder):\n",
        "#         img_path = os.path.join(path_to_folder, img_file)\n",
        "#         img = cv2.imread(img_path)\n",
        "#         img_g = img[:,:,1]  # Green channel\n",
        "\n",
        "#         # Ensure the image exists\n",
        "#         if img_g is not None:\n",
        "#             features = get_feature(img_g)\n",
        "#             data_list.append([img_file, class_label, *features])\n",
        "\n",
        "#     return data_list\n",
        "\n",
        "# def get_feature(img):\n",
        "#     clahe = cv2.createCLAHE(clipLimit=5)\n",
        "#     img_clahe = clahe.apply(img) + 30\n",
        "\n",
        "#     img_median = cv2.medianBlur(img_clahe, 5)\n",
        "\n",
        "#     img_graymatrix = graycomatrix(img_median, [1], [0, np.pi/4, np.pi/2, 3*np.pi/4])\n",
        "#     img_homogeneity = graycoprops(img_graymatrix, 'homogeneity')\n",
        "\n",
        "#     img_entropy = shannon_entropy(img_graymatrix)\n",
        "#     img_entropy = np.asarray([img_entropy])\n",
        "\n",
        "#     img_correlation = graycoprops(img_graymatrix, 'correlation')\n",
        "\n",
        "#     img_correlation_flattened = img_correlation.flatten()\n",
        "#     img_homogeneity_flattened = img_homogeneity.flatten()\n",
        "\n",
        "#     features = np.concatenate([img_correlation_flattened, img_homogeneity_flattened, img_entropy])\n",
        "\n",
        "#     return features\n",
        "\n",
        "# normal_path = '/content/drive/MyDrive/0'\n",
        "# proliferative_dr_path = '/content/drive/MyDrive/4'\n",
        "\n",
        "# data_list1 = feature_extraction(normal_path, 0)\n",
        "# data_list2 = feature_extraction(proliferative_dr_path, 1)\n",
        "\n",
        "# df = pd.DataFrame(data_list1)\n",
        "# df = pd.concat([pd.DataFrame(data_list1), pd.DataFrame(data_list2)], ignore_index=True)\n",
        "\n",
        "# df.rename(columns={0: \"image_names\", 1: \"label\"}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rlP9FzZ1H14V"
      },
      "outputs": [],
      "source": [
        "# df.head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "D-ZsTz9LIFEF"
      },
      "outputs": [],
      "source": [
        "# df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_7RS0QMgII9j"
      },
      "outputs": [],
      "source": [
        "# df.to_csv('Normal_VS_dr_features.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "collapsed": true,
        "id": "VfPr1SjrINqX"
      },
      "outputs": [],
      "source": [
        "# array=df.values\n",
        "# x_feature=array[:,2:]\n",
        "# y_label=array[:,1].astype('int')\n",
        "# print(x_feature.shape)\n",
        "# print(y_label.shape)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "YX3jjAf7ISmd"
      },
      "outputs": [],
      "source": [
        "# X_train,X_test,Y_train,Y_test=train_test_split(x_feature,y_label,test_size=0.10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "xHov9G0-IWj_"
      },
      "outputs": [],
      "source": [
        "# scaler_norm = MinMaxScaler()\n",
        "\n",
        "# X_train = scaler_norm.fit_transform(X_train)\n",
        "# X_test = scaler_norm.fit_transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "lxOnuWUSIbaA"
      },
      "outputs": [],
      "source": [
        "# model_SVC=SVC(kernel='linear',C=100,gamma=0.001)\n",
        "\n",
        "# kfold=KFold(n_splits=10, shuffle=True)\n",
        "# cv_results=cross_val_score(model_SVC,X_train,Y_train,cv=kfold,scoring='accuracy')\n",
        "# msg=\"%s %f (%f)\" % ('Training Accuracy: ',cv_results.mean(),cv_results.std())\n",
        "# print(msg)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Y4sHD-6wInxp"
      },
      "outputs": [],
      "source": [
        "# model_SVC=SVC()\n",
        "\n",
        "# kfold=KFold(n_splits=10)\n",
        "# param_grid = {'C': [1, 10, 100, 500, 1000],\n",
        "#               'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "#               'kernel': ['rbf']}\n",
        "\n",
        "# grid=GridSearchCV(estimator=model_SVC,param_grid=param_grid,scoring='accuracy',cv=kfold,verbose=3)\n",
        "# grid_result=grid.fit(X_train,Y_train)\n",
        "\n",
        "# print(\"Best: %f using %s\" % (grid_result.best_score_,grid_result.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "8i6v9b36Io_C"
      },
      "outputs": [],
      "source": [
        "# model_SVC = SVC(C=10,gamma=1, kernel='rbf')\n",
        "# model_SVC.fit(X_train,Y_train)\n",
        "\n",
        "# predictions=model_SVC.predict(X_test)\n",
        "\n",
        "# print(accuracy_score(Y_test,predictions))\n",
        "# print(confusion_matrix(Y_test,predictions))\n",
        "# print(classification_report(Y_test,predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "PdcPY3HEI3BZ"
      },
      "outputs": [],
      "source": [
        "# from sklearn.ensemble import VotingClassifier\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn.svm import SVC\n",
        "# from sklearn.tree import DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "88vBDwtFI4-X"
      },
      "outputs": [],
      "source": [
        "# models = [('LR', LogisticRegression(solver ='lbfgs', max_iter = 500)),\n",
        "#          ('SVC', SVC(C=10, gamma =1, kernel='rbf', probability=True)),\n",
        "#          ('DTC', DecisionTreeClassifier())]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "5c3kmLyxI8MP"
      },
      "outputs": [],
      "source": [
        "# ensemble = VotingClassifier(estimators = models, voting ='soft')\n",
        "# ensemble.fit(X_train, Y_train)\n",
        "# predictions = ensemble.predict(X_test)\n",
        "\n",
        "\n",
        "# print(accuracy_score(Y_test,predictions))\n",
        "# print(confusion_matrix(Y_test,predictions))\n",
        "# print(classification_report(Y_test,predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "lpUXy1anvRx5"
      },
      "outputs": [],
      "source": [
        "# !pip install deap\n",
        "\n",
        "# import numpy as np\n",
        "# import random\n",
        "# from deap import base, creator, tools, algorithms\n",
        "# from sklearn.svm import SVC\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.preprocessing import MinMaxScaler\n",
        "# from sklearn.metrics import accuracy_score\n",
        "\n",
        "# # Load Feature Matrix (Assuming x_feature, y_label are already prepared)\n",
        "# X = x_feature  # Features\n",
        "# y = y_label    # Labels\n",
        "\n",
        "# # Normalize Features\n",
        "# scaler = MinMaxScaler()\n",
        "# X = scaler.fit_transform(X)\n",
        "\n",
        "# # Split Data\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
        "\n",
        "# # Define Fitness Function (Accuracy of SVM Model)\n",
        "# def evaluate(individual):\n",
        "#     \"\"\" Compute fitness of an individual (selected features). \"\"\"\n",
        "#     selected_features = np.where(np.array(individual) == 1)[0]  # Get selected feature indices\n",
        "#     if len(selected_features) == 0:  # Prevent empty feature subset\n",
        "#         return 0,\n",
        "\n",
        "#     X_train_selected = X_train[:, selected_features]\n",
        "#     X_test_selected = X_test[:, selected_features]\n",
        "\n",
        "#     model = SVC(kernel='linear', C=10, gamma=0.001)\n",
        "#     model.fit(X_train_selected, y_train)\n",
        "#     predictions = model.predict(X_test_selected)\n",
        "#     acc = accuracy_score(y_test, predictions)\n",
        "\n",
        "#     return acc,  # GA expects a tuple\n",
        "\n",
        "# # Define Genetic Algorithm Parameters\n",
        "# POP_SIZE = 50  # Population Size\n",
        "# N_GEN = 30     # Number of Generations\n",
        "# MUTATION_RATE = 0.2\n",
        "# CROSSOVER_RATE = 0.5\n",
        "\n",
        "# # Define Optimization Type (Maximize Accuracy)\n",
        "# creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "# creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "\n",
        "# # Define Population\n",
        "# toolbox = base.Toolbox()\n",
        "# toolbox.register(\"attr_bool\", random.randint, 0, 1)  # Binary representation (1=select, 0=discard)\n",
        "# toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=X.shape[1])\n",
        "# toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "\n",
        "# # Register GA Operators\n",
        "# toolbox.register(\"evaluate\", evaluate)\n",
        "# toolbox.register(\"mate\", tools.cxTwoPoint)  # Crossover\n",
        "# toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.1)  # Mutation\n",
        "# toolbox.register(\"select\", tools.selTournament, tournsize=3)  # Selection\n",
        "\n",
        "# # Initialize Population\n",
        "# pop = toolbox.population(n=POP_SIZE)\n",
        "\n",
        "# # Run Genetic Algorithm\n",
        "# print(\"\\nRunning Genetic Algorithm for Feature Selection...\\n\")\n",
        "# for gen in range(N_GEN):\n",
        "#     offspring = algorithms.varAnd(pop, toolbox, cxpb=CROSSOVER_RATE, mutpb=MUTATION_RATE)\n",
        "#     fits = list(map(toolbox.evaluate, offspring))\n",
        "\n",
        "#     for ind, fit in zip(offspring, fits):\n",
        "#         ind.fitness.values = fit\n",
        "\n",
        "#     pop = toolbox.select(offspring, k=len(pop))\n",
        "\n",
        "# # Select Best Individual\n",
        "# best_ind = tools.selBest(pop, k=1)[0]\n",
        "# selected_features = np.where(np.array(best_ind) == 1)[0]\n",
        "\n",
        "# print(\"\\n✅ Selected Features:\", selected_features)\n",
        "# print(\"🎯 Best Accuracy:\", evaluate(best_ind)[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from skimage.feature import graycomatrix, graycoprops\n",
        "from skimage.measure import shannon_entropy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Feature Extraction Function\n",
        "def feature_extraction(path_to_folder, class_label):\n",
        "    data_list = []\n",
        "    for img_file in os.listdir(path_to_folder):\n",
        "        img_path = os.path.join(path_to_folder, img_file)\n",
        "        img = cv2.imread(img_path)\n",
        "\n",
        "        # Ensure image is loaded\n",
        "        if img is None:\n",
        "            continue\n",
        "\n",
        "        img_g = img[:, :, 1]  # Extract green channel\n",
        "        features = get_feature(img_g)\n",
        "        data_list.append([img_file, class_label, *features])\n",
        "\n",
        "    return data_list\n",
        "\n",
        "# Feature Computation Function\n",
        "def get_feature(img):\n",
        "    clahe = cv2.createCLAHE(clipLimit=5)\n",
        "    img_clahe = clahe.apply(img) + 30\n",
        "    img_median = cv2.medianBlur(img_clahe, 5)\n",
        "\n",
        "    # Compute Texture Features\n",
        "    img_graymatrix = graycomatrix(img_median, [1], [0, np.pi/4, np.pi/2, 3*np.pi/4])\n",
        "    img_homogeneity = graycoprops(img_graymatrix, 'homogeneity').flatten()\n",
        "    img_correlation = graycoprops(img_graymatrix, 'correlation').flatten()\n",
        "    img_entropy = np.array([shannon_entropy(img_graymatrix)])\n",
        "\n",
        "    # Combine all features\n",
        "    features = np.concatenate([img_correlation, img_homogeneity, img_entropy])\n",
        "    return features\n",
        "\n",
        "# Define Paths\n",
        "normal_path = '/content/drive/MyDrive/0'\n",
        "proliferative_dr_path = '/content/drive/MyDrive/4'\n",
        "\n",
        "# Extract Features from Images\n",
        "data_list1 = feature_extraction(normal_path, 0)\n",
        "data_list2 = feature_extraction(proliferative_dr_path, 1)\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data_list1 + data_list2, columns=[\"image_name\", \"label\"] + [f\"feature_{i}\" for i in range(len(data_list1[0]) - 2)])\n",
        "\n",
        "# Extract Features and Labels\n",
        "x_feature = df.iloc[:, 2:].values.astype(float)  # Features (Columns 2 onwards)\n",
        "y_label = df.iloc[:, 1].values.astype(int)       # Labels\n",
        "\n",
        "print(\"✅ Feature Matrix Shape:\", x_feature.shape)\n",
        "print(\"✅ Label Vector Shape:\", y_label.shape)\n",
        "\n",
        "# Normalize Features\n",
        "scaler = MinMaxScaler()\n",
        "x_feature = scaler.fit_transform(x_feature)\n",
        "\n",
        "# Split Dataset for Training and Testing\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(x_feature, y_label, test_size=0.2, random_state=7)\n",
        "\n",
        "print(\"✅ Train/Test Split Complete!\")\n"
      ],
      "metadata": {
        "id": "AYB_g2C8O0dS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "baa6419e-cb6c-4962-e947-983921f51326"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/0'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-a6a9b81724e0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# Extract Features from Images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mdata_list1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_extraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormal_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0mdata_list2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_extraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproliferative_dr_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-a6a9b81724e0>\u001b[0m in \u001b[0;36mfeature_extraction\u001b[0;34m(path_to_folder, class_label)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfeature_extraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mdata_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimg_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/0'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import random\n",
        "# from deap import base, creator, tools, algorithms\n",
        "# from sklearn.svm import SVC\n",
        "# from sklearn.metrics import accuracy_score\n",
        "\n",
        "# # Define Fitness Function for GA\n",
        "# def evaluate(individual):\n",
        "#     \"\"\" Compute fitness of an individual (selected features). \"\"\"\n",
        "#     selected_features = np.where(np.array(individual) == 1)[0]  # Get selected feature indices\n",
        "#     if len(selected_features) == 0:  # Prevent empty feature subset\n",
        "#         return 0,\n",
        "\n",
        "#     X_train_selected = X_train[:, selected_features]\n",
        "#     X_test_selected = X_test[:, selected_features]\n",
        "\n",
        "#     model = SVC(kernel='linear', C=10, gamma=0.001)\n",
        "#     model.fit(X_train_selected, Y_train)\n",
        "#     predictions = model.predict(X_test_selected)\n",
        "#     acc = accuracy_score(Y_test, predictions)\n",
        "\n",
        "#     return acc,  # GA expects a tuple\n",
        "\n",
        "# # Define Genetic Algorithm Parameters\n",
        "# POP_SIZE = 50  # Population Size\n",
        "# N_GEN = 30     # Number of Generations\n",
        "# MUTATION_RATE = 0.2\n",
        "# CROSSOVER_RATE = 0.5\n",
        "\n",
        "# # Define Optimization Type (Maximize Accuracy)\n",
        "# creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "# creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "\n",
        "# # Define Population\n",
        "# toolbox = base.Toolbox()\n",
        "# toolbox.register(\"attr_bool\", random.randint, 0, 1)  # Binary representation\n",
        "# toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=X_train.shape[1])\n",
        "# toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "\n",
        "# # Register GA Operators\n",
        "# toolbox.register(\"evaluate\", evaluate)\n",
        "# toolbox.register(\"mate\", tools.cxTwoPoint)  # Crossover\n",
        "# toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.1)  # Mutation\n",
        "# toolbox.register(\"select\", tools.selTournament, tournsize=3)  # Selection\n",
        "\n",
        "# # Initialize Population\n",
        "# pop = toolbox.population(n=POP_SIZE)\n",
        "\n",
        "# # Run Genetic Algorithm\n",
        "# print(\"\\n🚀 Running Genetic Algorithm for Feature Selection...\\n\")\n",
        "# for gen in range(N_GEN):\n",
        "#     offspring = algorithms.varAnd(pop, toolbox, cxpb=CROSSOVER_RATE, mutpb=MUTATION_RATE)  # Apply Crossover & Mutation\n",
        "#     fits = list(map(toolbox.evaluate, offspring))  # Evaluate fitness of each individual\n",
        "\n",
        "#     for ind, fit in zip(offspring, fits):\n",
        "#         ind.fitness.values = fit  # Assign fitness values\n",
        "\n",
        "#     pop = toolbox.select(offspring, k=len(pop))  # Select best individuals for next generation\n",
        "\n",
        "# # Select Best Individual\n",
        "# best_ind = tools.selBest(pop, k=1)[0]\n",
        "# selected_features = np.where(np.array(best_ind) == 1)[0]\n",
        "\n",
        "# print(\"\\n✅ Selected Features:\", selected_features)\n",
        "# print(\"🎯 Best Accuracy:\", evaluate(best_ind)[0])\n",
        "\n",
        "# # Use Best Features Selected by GA\n",
        "# X_train_selected = X_train[:, selected_features]\n",
        "# X_test_selected = X_test[:, selected_features]\n",
        "\n",
        "# # Train Final Model\n",
        "# final_model = SVC(kernel='linear', C=10, gamma=0.001)\n",
        "# final_model.fit(X_train_selected, Y_train)\n",
        "# predictions = final_model.predict(X_test_selected)\n",
        "\n",
        "# # Evaluate Performance\n",
        "# print(\"🔥 Final Model Accuracy:\", accuracy_score(Y_test, predictions))\n"
      ],
      "metadata": {
        "id": "VvtNsChoTUDF"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def compute_accuracy(agent, train_X, test_X, train_Y, test_Y):\n",
        "    \"\"\" Compute classification accuracy for selected features. \"\"\"\n",
        "    selected_features = np.where(agent == 1)[0]  # Get selected feature indices\n",
        "    if len(selected_features) == 0:  # Prevent empty feature subset\n",
        "        return 0\n",
        "\n",
        "    train_X_selected = train_X[:, selected_features]\n",
        "    test_X_selected = test_X[:, selected_features]\n",
        "\n",
        "    model = SVC(kernel='linear', C=10, gamma=0.001)\n",
        "    model.fit(train_X_selected, train_Y)\n",
        "    predictions = model.predict(test_X_selected)\n",
        "\n",
        "    return accuracy_score(test_Y, predictions)  # Return classification accuracy\n"
      ],
      "metadata": {
        "id": "hQWtSaGcUmx4"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_fitness(agent, train_X, test_X, train_Y, test_Y, weight_acc=0.9):\n",
        "    \"\"\" Compute fitness score considering accuracy and feature reduction. \"\"\"\n",
        "\n",
        "    agent = np.array(agent)  # Convert to NumPy array\n",
        "\n",
        "    weight_feat = 1 - weight_acc  # Balance between accuracy and feature reduction\n",
        "    num_features = len(agent)  # Fix: Use `len(agent)` instead of `agent.shape[0]`\n",
        "\n",
        "    acc = compute_accuracy(agent, train_X, test_X, train_Y, test_Y)  # Compute Accuracy\n",
        "    feat = (num_features - np.sum(agent)) / num_features  # Feature Reduction Score\n",
        "\n",
        "    fitness = weight_acc * acc + weight_feat * feat  # Weighted Fitness Score\n",
        "    return fitness,\n"
      ],
      "metadata": {
        "id": "JIBPlinGUnyG"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from deap import base, creator, tools, algorithms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "# Load Feature Matrix (Ensure `x_feature` and `y_label` are already extracted)\n",
        "X = x_feature\n",
        "y = y_label\n",
        "\n",
        "# Normalize Features\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split Dataset for Training and Testing\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
        "\n",
        "# Define Optimization Type (Maximize Fitness Score)\n",
        "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "\n",
        "# Define Population\n",
        "toolbox = base.Toolbox()\n",
        "toolbox.register(\"attr_bool\", random.randint, 0, 1)  # Binary Representation for Features (1=Select, 0=Ignore)\n",
        "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=X.shape[1])\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "\n",
        "# Register GA Operators\n",
        "toolbox.register(\"evaluate\", compute_fitness, train_X=X_train, test_X=X_test, train_Y=Y_train, test_Y=Y_test, weight_acc=0.9)\n",
        "toolbox.register(\"mate\", tools.cxTwoPoint)  # Two-Point Crossover\n",
        "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.1)  # Bit-Flip Mutation\n",
        "toolbox.register(\"select\", tools.selTournament, tournsize=3)  # Tournament Selection\n",
        "# Initialize Convergence Tracking\n",
        "convergence_curve = []\n",
        "\n",
        "# Initialize Population\n",
        "POP_SIZE = 30  # Population Size\n",
        "N_GEN = 60     # Number of Generations\n",
        "MUTATION_RATE = 0.2\n",
        "CROSSOVER_RATE = 0.5\n",
        "\n",
        "pop = toolbox.population(n=POP_SIZE)\n",
        "\n",
        "# Run Genetic Algorithm\n",
        "print(\"\\n🚀 Running Genetic Algorithm with `compute_fitness()`...\\n\")\n",
        "for gen in range(N_GEN):\n",
        "    offspring = algorithms.varAnd(pop, toolbox, cxpb=CROSSOVER_RATE, mutpb=MUTATION_RATE)  # Apply Crossover & Mutation\n",
        "    fits = list(map(toolbox.evaluate, offspring))  # Evaluate Fitness\n",
        "\n",
        "    for ind, fit in zip(offspring, fits):\n",
        "        ind.fitness.values = fit  # Assign Fitness Score\n",
        "\n",
        "    pop = toolbox.select(offspring, k=len(pop))  # Select Best Individuals for Next Generation\n",
        "    # Store Best Fitness Value for This Generation\n",
        "    best_fitness = max(fits)\n",
        "    convergence_curve.append(best_fitness)\n",
        "# Plot Convergence Curve\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(range(1, N_GEN + 1), convergence_curve, marker='o', linestyle='-', color='b', label='Fitness Score')\n",
        "plt.xlabel(\"Generation\")\n",
        "plt.ylabel(\"Best Fitness Score\")\n",
        "plt.title(\"Convergence Curve of Genetic Algorithm\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Select Best Individual\n",
        "best_ind = tools.selBest(pop, k=1)[0]\n",
        "selected_features = np.where(np.array(best_ind) == 1)[0]\n",
        "\n",
        "print(\"\\n✅ Selected Features:\", selected_features)\n",
        "print(\"🎯 Best Fitness Score:\", compute_fitness(best_ind, X_train, X_test, Y_train, Y_test, weight_acc=0.9)[0])\n",
        "\n",
        "# Use Best Features Selected by GA\n",
        "X_train_selected = X_train[:, selected_features]\n",
        "X_test_selected = X_test[:, selected_features]\n",
        "\n",
        "# Train Final Model with Selected Features\n",
        "final_model = SVC(kernel='linear', C=10, gamma=0.001)\n",
        "final_model.fit(X_train_selected, Y_train)\n",
        "predictions = final_model.predict(X_test_selected)\n",
        "\n",
        "# Evaluate Final Model\n",
        "final_accuracy = accuracy_score(Y_test, predictions)\n",
        "print(\"🔥 Final Model Accuracy:\", final_accuracy)\n",
        "# Ensure X_test uses only GA-selected features\n",
        "X_test_selected = X_test[:, selected_features]  # Select the same features used for training\n",
        "\n",
        "# Make Predictions\n",
        "predictions = final_model.predict(X_test_selected)  # Use only selected features\n",
        "\n",
        "# Evaluate Performance\n",
        "print(\"\\n🔥 **Final Model Accuracy:**\", accuracy_score(Y_test, predictions))\n",
        "print(\"\\n🧩 **Confusion Matrix:**\\n\", confusion_matrix(Y_test, predictions))\n",
        "print(\"\\n📊 **Classification Report:**\\n\", classification_report(Y_test, predictions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "EvjYmAK0UqHh",
        "outputId": "7866f5af-fd93-4375-81ca-aa135c1b9b21"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'deap'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-22036e57ab29>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdeap\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'deap'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Use Best Features Selected by GA\n",
        "X_train_selected = X_train[:, selected_features]\n",
        "X_test_selected = X_test[:, selected_features]\n",
        "\n",
        "# Define Base Models\n",
        "models = [\n",
        "    ('LR', LogisticRegression(solver='lbfgs', max_iter=500)),\n",
        "    ('SVC', SVC(C=10, gamma=1, kernel='rbf', probability=True)),\n",
        "    ('DTC', DecisionTreeClassifier())\n",
        "]\n",
        "\n",
        "# Create Ensemble Model (Soft Voting)\n",
        "ensemble = VotingClassifier(estimators=models, voting='soft')\n",
        "ensemble.fit(X_train_selected, Y_train)\n",
        "\n",
        "# Make Predictions\n",
        "predictions = ensemble.predict(X_test_selected)\n",
        "\n",
        "# Evaluate Ensemble Model\n",
        "ensemble_accuracy = accuracy_score(Y_test, predictions)\n",
        "print(\"\\n🔥 **Ensemble Model Accuracy:**\", ensemble_accuracy)\n",
        "print(\"\\n🧩 **Confusion Matrix:**\\n\", confusion_matrix(Y_test, predictions))\n",
        "print(\"\\n📊 **Classification Report:**\\n\", classification_report(Y_test, predictions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "rFZA-GaJUtic",
        "outputId": "d285f30c-02b0-4110-a68d-33daffefef76"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-dfcde3766ff0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Use Best Features Selected by GA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mX_train_selected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mX_test_selected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WSsitO7jXSSQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}